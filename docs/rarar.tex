\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{hyperref}
\usepackage[ruled,vlined]{algorithm2e}
\SetKwComment{Comment}{/* }{ */}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\lstset{
  basicstyle=\ttfamily\scriptsize,
  breaklines=true,
  columns=flexible,
  frame=single,
  numbers=left,
  numberstyle=\tiny\color{gray},
  commentstyle=\color{gray},
  keywordstyle=\color{blue},
  stringstyle=\color{purple},
  showstringspaces=false,
  breakatwhitespace=true,
  breakindent=0pt
}

\begin{document}

\title{RARAR: Random Access to RAR Archives}

\author{\IEEEauthorblockN{Elias Benbourenane}
	\IEEEauthorblockA{\textit{School of Computing and Information} \\
		\textit{University of Pittsburgh}\\
		Pittsburgh, USA \\
		elb222@pitt.edu}
}

\maketitle

\begin{abstract}
	This paper presents RARAR (Random Access RAR)\footnote{Available at: https://github.com/eliasbenb/RARAR.py}, a Python library that enables efficient access to RAR archives without requiring complete downloads. Our implementation supports multiple source types (HTTP URLs, local files, and file-like objects) while achieving significant bandwidth reduction for remote archive access. We discuss the technical challenges of parsing RAR formats, detail our architecture, and demonstrate bandwidth savings exceeding 99\% compared to traditional approaches. While currently limited to uncompressed files, our framework provides a foundation for future development in random-access archive handling.
\end{abstract}

\begin{IEEEkeywords}
	random access, RAR archives, Python library, HTTP Range requests, bandwidth optimization, file extraction
\end{IEEEkeywords}

\section{Introduction}
File archiving remains a fundamental practice for efficiently distributing file collections, particularly in cloud environments where bandwidth and storage constraints are critical considerations. The RAR format, despite its proprietary nature, continues to see widespread adoption due to its robust compression capabilities and widespread tool support. However, traditional RAR handling approaches require downloading entire archives before accessing individual files—a significant limitation when working with large remote archives.

Random access to archive contents would provide substantial benefits across numerous applications:
\begin{itemize}
	\item Previewing archive contents without full downloads
	\item Extracting specific files from large archives
	\item Streaming media content stored within archives
	\item Enabling search engine indexing of archive contents
\end{itemize}

RARAR addresses this limitation by providing a Python package that implements random access to RAR archives. While supporting local files, in-memory buffers, and other file-like objects, the library emphasizes HTTP sources due to their significant practical benefits. Our implementation leverages HTTP Range requests to selectively retrieve file segments, dramatically reducing bandwidth requirements and improving access efficiency.

The RARAR library is available as open-source software on GitHub: \url{https://github.com/eliasbenb/RARAR.py}. This paper presents the design, implementation, and performance characteristics of the library.

\subsection{Problem Statement}
Current approaches to accessing remote archives exhibit substantial inefficiencies, particularly as archive sizes increase. Consider extracting a 100KB document from a 100GB remote archive—the conventional workflow requires:

\begin{enumerate}
	\item Downloading the entire 100GB archive
	\item Extracting the 100KB target file
	\item Discarding 99.9999\% of the downloaded data
\end{enumerate}

This approach suffers from several critical issues:
\begin{itemize}
	\item Excessive bandwidth consumption and associated costs
	\item Storage limitations on client devices
	\item Time delays during the download process
	\item Environmental impact due to unnecessary data transfer
\end{itemize}

\subsection{Contribution}
This paper makes the following contributions:
\begin{itemize}
	\item A comprehensive analysis of the RAR file format from a random-access perspective
	\item Development of a Python library enabling random access to RAR archives via multiple source types
	\item Implementation of an efficient RAR parsing algorithm
	\item Empirical evaluation of bandwidth-saving potential in HTTP-based RAR access with HTTP Range requests
\end{itemize}

\section{Related Work}
\subsection{Existing RAR Handling Libraries}
Several libraries provide RAR archive handling capabilities, though none are designed for random access:

\begin{itemize}
	\item \textbf{UnRAR}: The official C library from RARLAB provides extraction functionality but requires local access to complete archives.

	\item \textbf{Python-rarfile}: A Python module wrapping the UnRAR library or command-line tools. While feature-complete, it requires full archive availability before extraction.
\end{itemize}

\subsection{Random Access in Other Archive Formats}
Research on random access has primarily focused on formats other than RAR:

\begin{itemize}
	\item \textbf{ZIP}: The ZIP format inherently supports efficient random access through its central directory structure located at the file's end. Libraries like Python's \texttt{zipfile} can parse this directory without downloading the entire archive, though full file access remains necessary for extraction.

	\item \textbf{LZOP}: The LZOP format enables random access to compressed data blocks, as demonstrated by the lzopfs project\cite{b5}, allowing efficient extraction of specific files. However, LZOP lacks the widespread adoption of RAR or ZIP.
\end{itemize}

\subsection{HTTP Range Requests in Content Delivery}
HTTP Range requests have proven valuable in various content delivery scenarios such as video streaming and resumable downloads. These applications demonstrate how requesting specific byte ranges optimizes data transfer and reduces bandwidth waste.

Our work extends these techniques to RAR archive access. To our knowledge, RARAR represents the first implementation of HTTP-based random access for RAR archives.

\section{Technical Background}

\subsection{RAR File Format}
The RAR archive format, developed by Eugene Roshal and maintained by win.rar GmbH, uses a proprietary structure that has been partially reverse-engineered by the community. The format consists of sequential blocks:

\begin{enumerate}
	\item Marker block (RAR signature)
	\item Archive header block
	\item File header blocks (one per file)
	\item End of archive block
\end{enumerate}

Each block follows a consistent structure (Figure~\ref{fig:block_header}) with a header containing block type, size, and various flags.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{fig/rar-block-header-diagram.png}}
	\caption{RAR Block Header Structure}
	\label{fig:block_header}
\end{figure}

\subsubsection{File Header Structure}
File headers are crucial for random access as they contain location and extraction information. The header extends the basic block structure with additional fields (Table~\ref{tab:file_header}), including file size, packed size, attributes, and filename—all essential for selective file access.

\begin{table}[htbp]
	\caption{RAR File Header Fields (after the basic header)}
	\begin{center}
		\footnotesize
		\begin{tabular}{|c|c|l|}
			\hline
			\textbf{Offset} & \textbf{Size} & \textbf{Description}                    \\
			\hline
			0x00            & 4 bytes       & Packed size (low part)                  \\
			\hline
			0x04            & 4 bytes       & Unpacked size (low part)                \\
			\hline
			0x08            & 1 byte        & Host OS (0=MS DOS, 1=OS/2, etc.)        \\
			\hline
			0x09            & 4 bytes       & File CRC32                              \\
			\hline
			0x0D            & 4 bytes       & File time (DOS format)                  \\
			\hline
			0x11            & 1 byte        & Unpacker version                        \\
			\hline
			0x12            & 1 byte        & Method (0x30=Store, 0x31=Fastest, etc.) \\
			\hline
			0x13            & 2 bytes       & Filename size                           \\
			\hline
			0x15            & 4 bytes       & File attributes                         \\
			\hline
			0x19            & Variable      & Optional high pack/unpack sizes         \\
			\hline
			                & Variable      & Filename (length from offset 0x13)      \\
			\hline
		\end{tabular}
		\label{tab:file_header}
	\end{center}
\end{table}

\subsection{HTTP Range Requests}
HTTP Range requests allow clients to request only a portion of a resource from a server. This capability is essential for our integration with remote files served through HTTP, as it enables requesting only the necessary parts of the RAR archive. The Range header in HTTP requests specifies which bytes of the resource to return, and servers respond with a 206 Partial Content status containing the desired file range.

\subsubsection{Range Request Specification}
The HTTP/1.1 protocol defines the Range header field in RFC 7233. A typical Range request header has the format:

\begin{lstlisting}
Range: bytes=start-end
\end{lstlisting}

Where \texttt{start} and \texttt{end} are byte positions. For example:
\begin{lstlisting}
Range: bytes=0-499    // First 500 bytes
Range: bytes=500-999  // Second 500 bytes
Range: bytes=-500     // Last 500 bytes
Range: bytes=500-     // All bytes from position 500
\end{lstlisting}

\subsubsection{Server Support Considerations}
Not all HTTP servers support Range requests. Our implementation detects whether a server supports this feature through a combination of:

\begin{itemize}
	\item Confirming a successful 206 or 200 response code when requesting a range.
	\item Finding an \texttt{Accept-Ranges} header in the response.
	\item Comparing the requested and returned content lengths.
\end{itemize}

\subsubsection{RAR Format Variations}
The RAR format has evolved through several versions (RAR 1.3, 2.0, 3.0, 4.0, and 5.0), each with subtle differences in header structures and compression algorithms. Our implementation focuses primarily on the most widely-used RAR 3.0 and 4.0 formats.

\subsubsection{Reverse Engineering Approach}
Without official documentation, our understanding of the RAR format was derived from:
\begin{itemize}
	\item Analysis of existing open-source implementations
	\item Community-documented specifications
	\item Testing against archive samples
\end{itemize}

\section{Design and Implementation}

\subsection{Architecture Overview}
RARAR is designed around the principle of minimal data transfer, downloading only the bytes necessary to accomplish specific tasks. The library consists of three main components:

\begin{enumerate}
	\item \textbf{Source Handlers}: Abstractions for file-like objects, including HTTP sources, local files, and memory buffers
	\item \textbf{Version Handlers}: A factory design pattern for automatic RAR version detection and handling
	\item \textbf{File Extractor}: Logic for parsing RAR headers and extracting individual files from archives
\end{enumerate}

\subsubsection{Source Handler Abstraction}
RARAR uses an adapter design pattern for accessing archive data regardless of the source. This abstraction allows the core parsing logic to remain independent of the archive's source (local file, HTTP URL, memory buffer, etc.).

Any source compatible with the \texttt{io} module in Python can be used as a source handler. The library provides built-in handlers for HTTP URLs and local files.

Specifically, the source handler must implement two methods for reading data:
\begin{itemize}
	\item \texttt{seek(position)}: Move to a specific byte position in the source
	\item \texttt{read(size)}: Read a specific number of bytes from the current position
\end{itemize}

\subsection{RAR Parsing Algorithms}
The core of RARAR is its ability to iterate through files in an archive without downloading the compressed content. The implementation parses only the necessary headers and file information, ignoring the compressed data to vastly reduce bandwidth usage.

Parsing file headers requires careful handling of variable-length fields and optional components. Algorithm~\ref{alg:parse_file_header} illustrates how we extract the necessary information while minimizing the number of reads.

The parser initially reads a 128-byte chunk that typically contains the entire header, avoiding multiple small reads. If the header exceeds this initial chunk (which is rare), we perform a single additional read for the remaining data. Variable-length fields like filenames are handled efficiently by first reading the fixed-size metadata that specifies their length, then extracting the exact bytes needed.

Optional components like high pack/unpack sizes are only read when the header flags indicate their presence. The parser uses a BytesIO stream to sequentially extract fields from the pre-read buffer rather than making separate read calls for each field. This buffered approach means that instead of making 10-15 separate reads for individual header fields, we typically need only one or two reads total, significantly reducing overhead, especially for remote sources using HTTP Range requests.

\begin{algorithm}[htb]
	\caption{Parsing File Headers}
	\label{alg:parse_file_header}
	\DontPrintSemicolon
	\KwIn{position in the file}
	\KwOut{file info object and next position}
	$headerChunk \gets ReadBytes(position, 128)$\;
	$headType, headFlags, headSize \gets ParseHeader(headerChunk[0:7])$\;
	\If{$headType \neq RAR3\_BLOCK\_FILE$}{
		\Return $null, position + headSize$\;
	}
	\If{$headSize > len(headerChunk)$}{
		$headerChunk \gets headerChunk + ReadBytes(position + 128, headSize - 128)$\;
	}
	$packSize, unpSize, method, fileCRC, nameSize \gets$\;
	$\qquad ParseFileFields(headerChunk[7:])$\;
	\If{$headFlags$ \& $FLAG\_HAS\_HIGH\_SIZE$}{
		$highPackSize, highUnpSize \gets ParseHighSizes(headerChunk)$\;
		$packSize \gets packSize + (highPackSize \ll 32)$\;
		$unpSize \gets unpSize + (highUnpSize \ll 32)$\;
	}
	$fileName \gets ParseFileName(headerChunk, nameSize, headFlags)$\;
	$isDirectory \gets (headFlags$ \& $FLAG\_DIRECTORY) = FLAG\_DIRECTORY$\;
	$dataOffset \gets position + headSize$\;
	$nextPos \gets dataOffset$\;
	\If{$headFlags$ \& $FLAG\_HAS\_DATA$}{
		$nextPos \gets nextPos + packSize$\;
	}
	$fileInfo \gets CreateFileInfo(fileName, unpSize, ...)$\;
	\Return $fileInfo, nextPos$\;
\end{algorithm}

\section{Performance Evaluation}

\subsection{Experimental Setup}
To evaluate RARAR's performance, we conducted a series of experiments using archives of various sizes and compositions. The testing environment consisted of:

\begin{itemize}
	\item \textbf{Client}: Python 3.13 on Ubuntu 24.04
	\item \textbf{Server}: RClone WebDav server on Ubuntu 24.04
	\item \textbf{Network}: 1Gbps LAN with simulated latency and bandwidth constraints using clumsy
	\item \textbf{Test Archives}: Multiple RAR archives ranging from 10MB to 50GB with varying numbers of files (10 to 250)
\end{itemize}

\subsection{Bandwidth Usage}
The primary advantage of RARAR is its minimal bandwidth requirements. We evaluated the library's performance by testing against archives of various sizes, measuring the amount of data transferred to perform common operations. The results demonstrate exceptional bandwidth efficiency and scalability.

Table~\ref{tab:bandwidth_comparison} summarizes the bandwidth savings achieved by RARAR for different archive sizes. The results demonstrate how RARAR can be used to efficiently access large archives. Notably, bandwidth usage is independent of archive size and instead scales linearly with the number of files in the archive, with each file requiring approximately 32KB of data transfer. This is due to RARAR's approach of parsing only file headers while ignoring data blocks.

For a 50GB archive containing 250 files, RARAR required only 7.82MB of data transfer to list all files in the archive. This represents a 99.98\% reduction in bandwidth usage compared to traditional methods requiring full archive download.

\begin{table}[htbp]
	\caption{Bandwidth Comparison: RARAR vs. Traditional Methods}
	\begin{center}
		\footnotesize
		\begin{tabular}{|c|c|c|c|}
			\hline
			\textbf{File Count} & \textbf{Archive Size} & \textbf{Bandwidth} & \textbf{Bandwidth Savings} \\
			\hline
			10                  & 10MB                  & 0.32MB             & 96.800\%                   \\
			\hline
			10                  & 100MB                 & 0.32MB             & 99.680\%                   \\
			\hline
			10                  & 1GB                   & 0.32MB             & 99.970\%                   \\
			\hline
			10                  & 10GB                  & 0.32MB             & 99.997\%                   \\
			\hline
			10                  & 50GB                  & 0.32MB             & 99.999\%                   \\
			\hline
			50                  & 10MB                  & 1.57MB             & 84.300\%                   \\
			\hline
			50                  & 100MB                 & 1.57MB             & 98.430\%                   \\
			\hline
			50                  & 1GB                   & 1.57MB             & 99.850\%                   \\
			\hline
			50                  & 10GB                  & 1.57MB             & 99.980\%                   \\
			\hline
			50                  & 50GB                  & 1.57MB             & 99.997\%                   \\
			\hline
			250                 & 10MB                  & 7.82MB             & 21.800\%                   \\
			\hline
			250                 & 100MB                 & 7.82MB             & 92.180\%                   \\
			\hline
			250                 & 1GB                   & 7.82MB             & 99.240\%                   \\
			\hline
			250                 & 10GB                  & 7.82MB             & 99.920\%                   \\
			\hline
			250                 & 50GB                  & 7.82MB             & 99.980\%                   \\
			\hline
		\end{tabular}
		\label{tab:bandwidth_comparison}
	\end{center}
\end{table}

\subsection{Operation Latency}
The operation latency of RARAR is influenced primarily by network conditions, particularly latency, due to the multiple small HTTP requests required for parsing archive structures. Our experiments measured the time taken to list files in RAR archives under different network latencies.

To simulate various network conditions, we used the clumsy tool to introduce artificial latency. The tests were conducted against a 100MB archive.

Table~\ref{tab:network_impact} shows the impact of varying network latencies on the time required to list the contents of RAR archives with different numbers of files. As expected, higher network latency results in increased operation time. For instance, listing the contents of an archive with 250 files takes approximately 411 ms with a network latency of 1 ms, but this increases to 33,961 ms with a latency of 100 ms.

Because of the large impact network latency has on RARAR's performance with HTTP sources, several optimizations have already been implemented:

\begin{itemize}
	\item Batch reading of headers where possible
	\item Predictive prefetching of likely-to-be-needed blocks
	\item Adaptive chunk sizing based on network conditions
\end{itemize}

\begin{table}[htbp]
	\caption{Network Condition Impact on RARAR Performance}
	\begin{center}
		\footnotesize
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Latency} & \textbf{Number of Files} & \textbf{Time to List} \\
			\hline
			1ms              & 10                       & 46ms                  \\
			\hline
			1ms              & 50                       & 102ms                 \\
			\hline
			1ms              & 250                      & 411ms                 \\
			\hline
			50ms             & 10                       & 1,587ms               \\
			\hline
			50ms             & 50                       & 5,089ms               \\
			\hline
			50ms             & 250                      & 22,636ms              \\
			\hline
			100ms            & 10                       & 2,374ms               \\
			\hline
			100ms            & 50                       & 7,639ms               \\
			\hline
			100ms            & 250                      & 33,961ms              \\
			\hline
		\end{tabular}
		\label{tab:network_impact}
	\end{center}
\end{table}

\subsection{Scalability Analysis}

As demonstrated in the results of Table~\ref{tab:bandwidth_comparison}, RARAR's bandwidth usage has perfect scalability with archive size, and, as demonstrated in Table~\ref{tab:network_impact}, the latency of operations scales linearly with the number of files in the archive. This means that RARAR can perfectly handle archives of any size and efficiently handle large numbers of files.

\section{Limitations and Future Work}

\subsection{Current Limitations}
Despite its advantages, RARAR currently has several limitations:

\begin{enumerate}
	\item \textbf{Compression Support}: Only uncompressed ("Store") files are supported. Files using RAR's compression algorithms cannot be extracted without downloading compressed blocks and implementing decompression.

	\item \textbf{Server Requirements}: Remote servers must support HTTP Range requests for RARAR to function correctly.

	\item \textbf{Multi-Part Archives}: Archives split across multiple files are not yet supported.

	\item \textbf{Encrypted Archives}: Password-protected archives cannot be processed due to the need to decrypt the entire archive structure.
\end{enumerate}

\subsection{Future Work}
Several avenues for extending RARAR's capabilities include:

\subsubsection{Compressed File Support}
Implementing support for the most common RAR compression methods would greatly expand the library's utility. This would require:
\begin{itemize}
	\item Implementing or integrating RAR decompression algorithms
	\item Analyzing whether partial decompression from arbitrary positions is feasible
	\item Optimizing to minimize the amount of compressed data needed
\end{itemize}

One promising approach would be to develop a partial decompression strategy that identifies blocks containing the target file and downloads only the necessary compressed blocks. From there, the library could perform targeted decompression of those blocks, allowing for random access to compressed files.

\subsubsection{RAR5 Support}
RAR5 is the latest version of the RAR format, introducing new features and compression methods. Implementing RAR5 support would expand RARAR's versatility and would require a rework of the header parsing logic to accommodate the new block structures and compression methods.

The current implementation of RARAR uses a factory design pattery, designed to be extensible, allowing for the addition of new version handlers as needed. This would enable RARAR to support both RAR3 and RAR5 formats seamlessly.

\subsubsection{Integration into Web Servers}
Integrating RARAR with web-based file servers was our original inspiration for the project. It could enable servers to much more efficiently serve files. We envision a system where:

\begin{itemize}
	\item A web server can serve RAR archives with random access capabilities
	\item Clients can request specific files or ranges from the archive
	\item The server handles decompression and file extraction on-the-fly
\end{itemize}

\section{Conclusion}
RARAR.py represents a novel approach to working with RAR archives, enabling random access with minimal bandwidth requirements. By carefully parsing RAR file structures and leveraging HTTP Range requests, our solution enables efficient listing and extraction of files from remote archives without downloading entire archives.

The demonstrated bandwidth savings in accessing a 50GB archive while transferring only 0.32MB of data highlights the significant efficiency improvements possible with this approach. While current limitations restrict the library to uncompressed files, the foundation established by RARAR opens pathways for future work on more comprehensive random access archive handling.

This project contributes both a practical tool for developers working with remote archives and demonstrates techniques that could be applied to other archive formats to enable more efficient remote file access.

\begin{thebibliography}{00}
	\bibitem{b1} E. Benbourenane, "RARAR.py: Random Access RAR," GitHub repository, Available: https://github.com/eliasbenb/RARAR.py, 2025.
	\bibitem{b2} E. Roshal, "RAR archive file format," Technical Specification, RARLAB, 2019.
	\bibitem{b3} R. Fielding et al., "Hypertext Transfer Protocol (HTTP/1.1): Range Requests," RFC 7233, Internet Engineering Task Force, June 2014.
	\bibitem{b4} Python Software Foundation, "io — Core tools for working with streams," Python Documentation, version 3.13, 2024.
	\bibitem{b5} D. Vasilevsky, "lzopfs: A FUSE filesystem for transparent random access to compressed LZOP archives," GitHub repository, Available: https://github.com/vasi/lzopfs, 2011.
\end{thebibliography}

\end{document}